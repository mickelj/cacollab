{
  "name": "node-tokenizer",
  "version": "0.0.0",
  "description": "A tokenizer written in JavaScript.",
  "main": "tokenizer.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/nickdesaulniers/node-tokenizer.git"
  },
  "keywords": [
    "tokenizer",
    "token",
    "lex",
    "lexer",
    "lexical",
    "analysis"
  ],
  "author": {
    "name": "Nick Desaulniers"
  },
  "license": "MPL2.0",
  "readmeFilename": "README.md",
  "readme": "# tokenizer #\nA simple tokenizer written in javascript for Node.JS\n\n### Example ###\n```javascript\nvar fs = require('fs');\nvar tokenizer = require('./tokenizer');\n\ntokenizer.debug = true;\ntokenizer.rule('newline', /^\\n/);\ntokenizer.rule('whitespace', /^\\s+/);\ntokenizer.rule('word', /^[^\\s]+/);\nvar tokens = tokenizer.tokenize(fs.readFileSync('./nick.n', 'utf8'));\n\nconsole.log('Parsed ' + tokens.length + ' tokens');\n```\n\nwhere the source file is:\n```\nfn hello_world\n  puts 'hello world'\n```\n\n\nwill output:\n\n```\nStarting tokenizer --\nfn hello_world\n  puts 'hello world'\n\n--                    --\nword token: fn\nwhitespace token:  \nword token: hello_world\nnewline token: \n\nwhitespace token:   \nword token: puts\nwhitespace token:  \nword token: 'hello\nwhitespace token:  \nword token: world'\nnewline token: \n\n-- Tokenizing complete --\n[ 'fn',\n  ' ',\n  'hello_world',\n  '\\n',\n  '  ',\n  'puts',\n  ' ',\n  '\\'hello',\n  ' ',\n  'world\\'',\n  '\\n' ]\n--                     --\nParsed 11 tokens\n",
  "_id": "node-tokenizer@0.0.0",
  "dist": {
    "shasum": "d3f06b61e8e7241a5b2f31e412ab361cf2ecec93",
    "tarball": "https://registry.npmjs.org/node-tokenizer/-/node-tokenizer-0.0.0.tgz"
  },
  "_npmVersion": "1.1.65",
  "_npmUser": {
    "name": "wangstabill",
    "email": "wangstabill@snet.net"
  },
  "maintainers": [
    {
      "name": "wangstabill",
      "email": "wangstabill@snet.net"
    }
  ],
  "directories": {},
  "_shasum": "d3f06b61e8e7241a5b2f31e412ab361cf2ecec93",
  "_resolved": "https://registry.npmjs.org/node-tokenizer/-/node-tokenizer-0.0.0.tgz",
  "_from": "node-tokenizer@latest"
}
